{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  A Critical Review of Object Detection using Convolution Neural Network [here](https://ieeexplore.ieee.org/abstract/document/8681010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This study aims to review CNN methods for object detection by highlighting the contribution and challenges from few recent research papers. Also how well to use these CNN techniques in combination to other methods for best suited results with other. Better performance such as increased accuracy, fast processing reduce error rates also introduced few new concernes and issues in parallel regarding the discussed methods such  as time consumption, anonymous behavior of Neural Network. To address these issues a conceptual model is presented using CNN and Lease Square Support Vector Machine(LS-SVM).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. ImageNet classification with deep convolutional neural networks [here](https://dl.acm.org/doi/abs/10.1145/3065386)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*a simple implementaion*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPool2D, Input, Flatten, Dense\n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "xs = []\n",
    "ys = []\n",
    "for i in range(1, 6):\n",
    "        \n",
    "        filename = './datasets/cifar-10-batches-py/data_batch_'+str(i)\n",
    "        with open(filename, 'rb') as f:\n",
    "            datadict = pickle.load(f, encoding='bytes')\n",
    "            X = datadict[b'data']\n",
    "            Y = datadict[b'labels']\n",
    "            X = X.reshape(10000, 3, 32, 32)\n",
    "            X = X.transpose(0, 2, 3, 1).astype('float')\n",
    "            Y = np.array(Y)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)\n",
    "\n",
    "X_train = np.concatenate(xs)\n",
    "Y_train = np.concatenate(ys)\n",
    "del X, Y, xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './datasets/cifar-10-batches-py/test_batch'\n",
    "with open(filename, 'rb') as f:\n",
    "    datadict = pickle.load(f, encoding='bytes')\n",
    "    X_test = datadict[b'data']\n",
    "    Y_test = datadict[b'labels']\n",
    "    X_test = X_test.reshape(10000, 3, 32, 32)\n",
    "    X_test = X_test.transpose(0, 2, 3, 1).astype('float')\n",
    "    Y_test = np.array(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3) (10000,) (50000, 32, 32, 3) (50000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape,Y_test.shape, X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_one_hot = to_categorical(Y_train)\n",
    "Y_test_one_hot = to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myInput = Input(shape=(32,32,3))\n",
    "conv1 = Conv2D(16,3, activation='relu',padding='same')(myInput)\n",
    "pool1 = MaxPool2D(pool_size=2)(conv1)\n",
    "conv2 = Conv2D(32,3,activation='relu',padding='same')(pool1)\n",
    "pool2 = MaxPool2D(pool_size=2)(conv2)\n",
    "conv3 = Conv2D(32,3,activation='relu',padding='same')(pool2)\n",
    "conv4 = Conv2D(32,3,activation='relu',padding='same')(conv3)\n",
    "conv5 = Conv2D(32,3,activation='relu',padding='same')(conv4)\n",
    "pool5 = MaxPool2D(pool_size=2)(conv5)\n",
    "flat = Flatten()(pool5)\n",
    "fc6 = Dense(1000, activation='relu')(flat)\n",
    "fc7 = Dense(500, activation='relu')(fc6)\n",
    "out_layer = Dense(10, activation='softmax')(fc7)\n",
    "\n",
    "myModel = Model(myInput, out_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1118 06:16:54.275384  5108 deprecation.py:323] From c:\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1118 06:16:54.440494  5108 deprecation_wrapper.py:119] From c:\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 73s 2ms/step - loss: 1.7503 - acc: 0.3538 - val_loss: 1.5777 - val_acc: 0.4216\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 71s 2ms/step - loss: 1.4011 - acc: 0.4901 - val_loss: 1.3801 - val_acc: 0.5060\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 63s 2ms/step - loss: 1.2152 - acc: 0.5623 - val_loss: 1.3015 - val_acc: 0.5288\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 61s 2ms/step - loss: 1.0888 - acc: 0.6136 - val_loss: 1.0498 - val_acc: 0.6264\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 61s 2ms/step - loss: 0.9739 - acc: 0.6550 - val_loss: 1.0806 - val_acc: 0.6165\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 62s 2ms/step - loss: 0.8984 - acc: 0.6816 - val_loss: 1.0010 - val_acc: 0.6487\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 61s 2ms/step - loss: 0.8280 - acc: 0.7118 - val_loss: 1.0082 - val_acc: 0.6532\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 61s 2ms/step - loss: 0.7482 - acc: 0.7361 - val_loss: 0.9646 - val_acc: 0.6712\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 60s 2ms/step - loss: 0.6824 - acc: 0.7624 - val_loss: 0.9158 - val_acc: 0.6828\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 60s 2ms/step - loss: 0.6211 - acc: 0.7820 - val_loss: 0.9003 - val_acc: 0.6987\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 65s 2ms/step - loss: 0.5529 - acc: 0.8062 - val_loss: 0.9175 - val_acc: 0.7007\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 62s 2ms/step - loss: 0.4844 - acc: 0.8321 - val_loss: 0.9363 - val_acc: 0.6998\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 62s 2ms/step - loss: 0.4234 - acc: 0.8516 - val_loss: 0.9564 - val_acc: 0.7044\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 62s 2ms/step - loss: 0.3550 - acc: 0.8770 - val_loss: 1.0042 - val_acc: 0.7036\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 65s 2ms/step - loss: 0.2873 - acc: 0.8985 - val_loss: 1.1059 - val_acc: 0.6999\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 68s 2ms/step - loss: 0.2482 - acc: 0.9115 - val_loss: 1.2629 - val_acc: 0.6892\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 64s 2ms/step - loss: 0.2051 - acc: 0.9274 - val_loss: 1.2612 - val_acc: 0.6969\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 64s 2ms/step - loss: 0.1480 - acc: 0.9485 - val_loss: 1.4107 - val_acc: 0.6885\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 66s 2ms/step - loss: 0.1437 - acc: 0.9502 - val_loss: 1.4907 - val_acc: 0.6906\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 65s 2ms/step - loss: 0.1106 - acc: 0.9611 - val_loss: 1.6222 - val_acc: 0.6952\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 72s 2ms/step - loss: 0.1103 - acc: 0.9607 - val_loss: 1.5824 - val_acc: 0.6983\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 76s 2ms/step - loss: 0.0937 - acc: 0.9671 - val_loss: 1.7035 - val_acc: 0.6886\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 70s 2ms/step - loss: 0.0870 - acc: 0.9693 - val_loss: 1.6753 - val_acc: 0.7034\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 69s 2ms/step - loss: 0.0872 - acc: 0.9694 - val_loss: 1.7024 - val_acc: 0.7040\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 67s 2ms/step - loss: 0.0609 - acc: 0.9794 - val_loss: 1.8635 - val_acc: 0.6972\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 65s 2ms/step - loss: 0.0869 - acc: 0.9701 - val_loss: 1.7440 - val_acc: 0.6932\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 69s 2ms/step - loss: 0.0808 - acc: 0.9722 - val_loss: 1.8690 - val_acc: 0.6878\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 69s 2ms/step - loss: 0.0899 - acc: 0.9686 - val_loss: 1.8703 - val_acc: 0.6953\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 70s 2ms/step - loss: 0.0568 - acc: 0.9804 - val_loss: 2.0685 - val_acc: 0.6836\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 65s 2ms/step - loss: 0.0495 - acc: 0.9831 - val_loss: 2.0445 - val_acc: 0.6940\n"
     ]
    }
   ],
   "source": [
    "network_history = myModel.fit(X_train, Y_train_one_hot, batch_size=256, epochs=30, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 12s 1ms/step\n",
      "1.9988726768493652\n",
      "0.695\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = myModel.evaluate(X_test, Y_test_one_hot)\n",
    "print(test_loss)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import image\n",
    "# cat = image.imread('./datasets/cat.jpg')\n",
    "# dog = image.imread('./datasets/dog.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 5]\n"
     ]
    }
   ],
   "source": [
    "# import cv2\n",
    "# cat = cv2.resize(cat, dsize=(32, 32), interpolation=cv2.INTER_CUBIC)\n",
    "# dog = cv2.resize(dog, dsize=(32, 32), interpolation=cv2.INTER_CUBIC)\n",
    "# test = np.array([dog, cat])\n",
    "# test_labels_p = myModel.predict(test)\n",
    "# test_labels_p = np.argmax(test_labels_p, axis=1)\n",
    "# print(test_labels_p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Deep Neural Networks for Object Detection [here](https://proceedings.neurips.cc/paper/2013/hash/f7cade80b7cc92b991cf4d2806d6bd78-Abstract.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. DeepID-Net: Object Detection with Deformable Part Based Convolutional Neural Networks [here](https://ieeexplore.ieee.org/abstract/document/7506134)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition [here](https://ieeexplore.ieee.org/abstract/document/7005506)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Region-Based Convolutional Networks for Accurate Object Detection and Segmentation [here](https://ieeexplore.ieee.org/abstract/document/7112511)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
